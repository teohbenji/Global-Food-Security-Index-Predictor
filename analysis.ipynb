{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Contribution Table\n",
    "\n",
    "| Name                      | Student ID | Contributions   |\n",
    "|---------------------------|------------|------------------|\n",
    "| Benjamin Teoh Tian Hao    | 1007197    | Q3               |\n",
    "| Dominic Lim Wei Ping      | 1006863    | Q0, 1, 5         |\n",
    "| Khoo Teng Jin             | 1007104    | Q4               |\n",
    "| Lee Sean Lee Sheng        | 1006903    | Q2, 5            |\n",
    "| Wong Jun Ming, Ivan       | 1006927    | Q2, 6            |\n",
    "\n",
    "### Problem Statement\n",
    "<!--Background description of the problem-->\n",
    "Food security is defined as people having reliable access to eve (The World Bank, 2023). During the global COVID pandemic, food security \n",
    "\n",
    "The World Bank. (2023, August 28). What is food security? there are four dimensions. World Bank. https://www.worldbank.org/en/topic/agriculture/brief/food-security-update/what-is-food-security \n",
    "\n",
    "\n",
    "<!--Persona-->\n",
    "\n",
    "With that in mind, our final problem statement is: How might we  predict the food security index of an Asian country during a global pandemic based on their socio-economic indicators such as Human Development Index(HDI) ?\n",
    "\n",
    "### Data\n",
    "<!--Data sources --> \n",
    "<!--Explain how we collated the data and combined it into a single dataset for use-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncleaned_df = pd.read_csv(\"dataset.csv\")\n",
    "# display(uncleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset cleaning\n",
    "\n",
    "#Rename columns to acronyms\n",
    "uncleaned_df = uncleaned_df.rename(columns={\n",
    "    'Global Food Security Index (GFSI)': 'GFSI',\n",
    "    'Human Development Index (HDI)': 'HDI',\n",
    "    'Corruption Index (CI)': 'CI',\n",
    "    'GDP per capita (GDP)': 'GDP',\n",
    "    'Cost of Living Index (COL)': 'COL',\n",
    "    'Healthcare Index (HI)': 'HI'\n",
    "})\n",
    "\n",
    "#Delete rows containing NaN values\n",
    "df = uncleaned_df.replace(\"-\", np.NaN).dropna()\n",
    "df = df.drop(['Country'], axis=1)\n",
    "\n",
    "df = df.astype(float) #convert all values in df to float\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter chart showing relationship between HDI and GFSI\n",
    "\n",
    "# plt.scatter(df[\"HDI\"] ,df[\"GFSI\"])\n",
    "# plt.xlabel(\"HDI\")\n",
    "# plt.ylabel(\"GFSI\")\n",
    "# plt.title(\"HDI vs GFSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Scatter chart showing relationship between CI and GFSI\n",
    "# plt.scatter(df[\"CI\"] ,df[\"GFSI\"])\n",
    "# plt.xlabel(\"CI\")\n",
    "# plt.ylabel(\"GFSI\")\n",
    "# plt.title(\"CI vs GFSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter chart showing relationship between GDP and GFSI\n",
    "\n",
    "# plt.scatter(df[\"GDP\"] ,df[\"GFSI\"])\n",
    "# plt.xlabel(\"GDP\")\n",
    "# plt.ylabel(\"GFSI\")\n",
    "# plt.title(\"GDP vs GFSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter chart showing relationship between COL and GFSI\n",
    "\n",
    "# plt.scatter(df[\"COL\"] ,df[\"GFSI\"])\n",
    "# plt.xlabel(\"COL\")\n",
    "# plt.ylabel(\"GFSI\")\n",
    "# plt.title(\"COL vs GFSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter chart showing relationship between HI and GFSI\n",
    "\n",
    "# plt.scatter(df[\"HI\"] ,df[\"GFSI\"])\n",
    "# plt.xlabel(\"HI\")\n",
    "# plt.ylabel(\"GFSI\")\n",
    "# plt.title(\"HI vs GFSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for preparing test and train datasets\n",
    " \n",
    "def get_features_targets(df, feature_names, target_names):\n",
    "    df_feature = pd.DataFrame(df[feature_names])\n",
    "    df_target = pd.DataFrame(df[target_names])\n",
    "    return df_feature, df_target\n",
    "\n",
    "def normalize_z(dfin, column_means=None, column_stds=None):\n",
    "    if column_means is None:\n",
    "        column_means = dfin.mean(axis=0) # creates 1 mean per column\n",
    "    if column_stds is None:\n",
    "        column_stds = dfin.std(axis=0) # creates 1 std dev per column\n",
    "    dfout = (dfin - column_means)/column_stds\n",
    "        \n",
    "    return dfout, column_means, column_stds\n",
    "\n",
    "def normalize_minmax(dfin, columns_mins = None, columns_maxs = None):\n",
    "    dfin_copy = dfin.copy()\n",
    "\n",
    "    if columns_mins == None:\n",
    "        columns_mins = dfin_copy.min(axis=0)\n",
    "        \n",
    "    if isinstance(columns_mins, list):\n",
    "        columns_mins = np.array(columns_mins)\n",
    "    \n",
    "    if columns_maxs == None:\n",
    "        columns_maxs = dfin_copy.max(axis=0)\n",
    "\n",
    "    if isinstance(columns_maxs, list):\n",
    "        columns_maxs = np.array(columns_maxs)\n",
    "    \n",
    "\n",
    "    dfout = (dfin_copy - columns_mins) / (columns_maxs - columns_mins)\n",
    "\n",
    "    return dfout, columns_mins, columns_maxs\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
    "    \n",
    "    indexes = df_feature.index\n",
    "    n = int(len(indexes) * test_size)\n",
    "    \n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    test_indexes = np.random.choice(indexes, n, replace=False)\n",
    "    train_indexes = list(set(indexes) - set(test_indexes))\n",
    "    \n",
    "    df_feature_train = df_feature.loc[train_indexes,:]\n",
    "    df_target_train = df_target.loc[train_indexes,:]\n",
    "    \n",
    "    df_feature_test = df_feature.loc[test_indexes,:]\n",
    "    df_target_test = df_target.loc[test_indexes,:]\n",
    "    \n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost and gradient descent functions for regression\n",
    "\n",
    "def calc_linreg(X, beta):\n",
    "    return X @ beta # matrix multiplication\n",
    "\n",
    "def compute_cost_linreg(X, y, beta):\n",
    "    m = X.shape[0] # m is number of values\n",
    "    y_pred = calc_linreg(X,beta)\n",
    "    error = y_pred - y\n",
    "    cost = 1/(2*m) * (error.T @ error) # results in a 2D 1x1 matrix\n",
    "    J = cost[0,0] # extract scalar value from 2D 1x1 matrix\n",
    "    \n",
    "    return J\n",
    "\n",
    "def prepare_feature(df_feature):\n",
    "    m = df_feature.shape[0]\n",
    "\n",
    "    # convert df to numpy array if not df\n",
    "    if isinstance(df_feature, pd.DataFrame):\n",
    "        np_feature = df_feature.to_numpy() \n",
    "    else:\n",
    "        np_feature = df_feature\n",
    "    \n",
    "    # Joins 2D ones array of size (m,1) to the left of np_feature  \n",
    "    X = np.concatenate((np.ones((m,1)), np_feature), axis = 1)\n",
    "    return X\n",
    "\n",
    "def prepare_target(df_target):\n",
    "    # convert df to numpy array if not df\n",
    "    if isinstance(df_target, pd.DataFrame):\n",
    "        return df_target.to_numpy()\n",
    "    else:\n",
    "        return df_target\n",
    "\n",
    "def gradient_descent_linreg(X, y, beta, alpha, num_iters):\n",
    "    m = X.shape[0]\n",
    "    J_storage = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        y_pred = calc_linreg(X,beta)\n",
    "        error = y_pred - y\n",
    "\n",
    "        dev = X.T @ error #partial derivative of J\n",
    "        beta = beta - (alpha/m) * dev # calculate new beta\n",
    "        J_storage.append(compute_cost_linreg(X,y,beta)) #stores cost value at each iteration\n",
    "        \n",
    "    return beta, np.array(J_storage)\n",
    "\n",
    "def predict_linreg(df_feature, beta, means=None, stds=None):\n",
    "    feature,means,stds = normalize_z(df_feature,means,stds)\n",
    "    X = prepare_feature(feature)\n",
    "    y_pred = calc_linreg(X, beta)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to test accuracy of model\n",
    "\n",
    "def r2_score(y, ypred):\n",
    "    error = y - ypred\n",
    "    ssres = np.sum(error**2)\n",
    "\n",
    "    y_mean = np.mean(y)\n",
    "    diff = y - y_mean\n",
    "    sstot = np.sum(diff**2)\n",
    "\n",
    "    return 1 - (ssres/sstot)\n",
    "\n",
    "def mean_squared_error(target, pred):\n",
    "    n = target.shape[0]\n",
    "    error = target - pred\n",
    "    return 1/n * np.sum(error**2)\n",
    "\n",
    "def root_mean_squared_error(target, pred):\n",
    "    n = target.shape[0]\n",
    "    error = target - pred\n",
    "    return pow((1/n * np.sum(error**2)), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression: Predict GFSI using HDI, CI, GDP, COL, HI\n",
    "\n",
    "# Get features and targets from data frame\n",
    "columns = [\"HDI\", \"CI\", \"GDP\", \"COL\", \"HI\"]\n",
    "df_feature, df_target = get_features_targets(df, columns, [\"GFSI\"])\n",
    "\n",
    "# Split the data into training and test data sets\n",
    "df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(df_feature, df_target, random_state = 100, test_size = 0.3)\n",
    "\n",
    "# Normalize the feature using z normalization\n",
    "df_feature_train_z,_ ,_ = normalize_z(df_feature_train)\n",
    "\n",
    "X = prepare_feature(df_feature_train_z)\n",
    "target = prepare_target(df_target_train)\n",
    "\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "beta = np.zeros((6,1)) #NOTE: np.zeros((k,1)), k = no. of features + 1 \n",
    "\n",
    "# call the gradient_descent function\n",
    "beta, J_storage = gradient_descent_linreg(X, target, beta, alpha, iterations)\n",
    "\n",
    "# call the predict method to get the predicted values\n",
    "pred = predict_linreg(df_feature_test, beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6739953365874148\n",
      "33.950689112636965\n",
      "5.826721986901123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6.33608516e+01],\n",
       "       [ 6.47148321e+00],\n",
       "       [ 1.53153458e+00],\n",
       "       [ 1.97364204e-01],\n",
       "       [-3.24760210e-01],\n",
       "       [-4.22354158e-02]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing of model\n",
    "target = prepare_target(df_target_test) #recalibrate target value to test target values\n",
    "\n",
    "print(r2_score(target, pred))\n",
    "print(mean_squared_error(target, pred))\n",
    "print(root_mean_squared_error(target, pred))\n",
    "display(beta)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
